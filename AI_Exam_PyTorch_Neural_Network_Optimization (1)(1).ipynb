{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "AI_Exam_PyTorch_Neural_Network_Optimization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMgQm9Yezxun"
      },
      "source": [
        "#Final Exam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtkiUAA1DMLq"
      },
      "source": [
        "For the final exam, you need to use the code below and make experiments with different hyperparameter settings (number of neurons, activation function, optimizer, learning rate, batch size, and epochs). \n",
        "\n",
        "You need to make 10 different experiments and record the parameter settings for each experiment, as well as the obtained results.\n",
        "\n",
        "On the project defence, you will need to understand the code and answer questions related to specific part of the code, neural networks and hyperparameters. For example, what is Sigmoid function, how it works, what computations are performed in neurons, etc.\n",
        "\n",
        "You will need to turn in your *.ipynb file and the recorded results in excel spreadsheeet 24h before the exam."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MpJx5mzkGmw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPg9FTQYXWhu"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqKzCNlzXYcg"
      },
      "source": [
        "# Define a transform to normalize the data\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc6VBADWXfPT"
      },
      "source": [
        "## Building the network\n",
        "\n",
        "Each image in MNIST is 28x28 which is a total of 784 pixels, and there are 10 classes. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "x5khFI1EbMrH"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "smLZdKSsbM_D"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOQclNazXbU8"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n",
        "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
        "        \n",
        "            Arguments\n",
        "            ---------\n",
        "            input_size: integer, size of the input\n",
        "            output_size: integer, size of the output layer\n",
        "            hidden_layers: list of integers, the sizes of the hidden layers\n",
        "            drop_p: float between 0 and 1, dropout probability\n",
        "        '''\n",
        "        super().__init__()\n",
        "        # Add the first layer, input to a hidden layer\n",
        "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
        "        \n",
        "        # Add a variable number of more hidden layers\n",
        "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
        "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
        "        \n",
        "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=drop_p)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        ''' Forward pass through the network, returns the output logits '''\n",
        "        \n",
        "        # Forward through each layer in `hidden_layers`, with ReLU activation and dropout\n",
        "        for linear in self.hidden_layers:\n",
        "            x = F.relu(linear(x))\n",
        "            #activation function\n",
        "            x = self.dropout(x)\n",
        "        \n",
        "        x = self.output(x)\n",
        "        \n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D_u2CalXzyT"
      },
      "source": [
        "# Train the network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3INvTkWQXxms"
      },
      "source": [
        "# Create the network, define the criterion and optimizer\n",
        "model = Network(784, 10, [516, 256], drop_p=0.5)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) \n",
        "#learning rate\n",
        "#optim adam SGD Adam"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSHcVVu-X1zk"
      },
      "source": [
        "# Implement a function for the validation pass\n",
        "def validation(model, testloader, criterion):\n",
        "    test_loss = 0\n",
        "    accuracy = 0\n",
        "    for images, labels in testloader:\n",
        "\n",
        "        images.resize_(images.shape[0], 784)\n",
        "\n",
        "        output = model.forward(images)\n",
        "        test_loss += criterion(output, labels).item()\n",
        "\n",
        "        # we get the log probability from the forward pass and take the exponential\n",
        "        ps = torch.exp(output)\n",
        "        equality = (labels.data == ps.max(dim=1)[1])\n",
        "        accuracy += equality.type(torch.FloatTensor).mean()\n",
        "    \n",
        "    return test_loss, accuracy"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By0X09aXX3-2",
        "outputId": "803f0c22-9777-4ce8-b2ab-af205a2b4f02"
      },
      "source": [
        "epochs = 4\n",
        "#range betwen\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 40\n",
        "\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "  model.train()\n",
        "  for images, labels in trainloader:\n",
        "    steps += 1\n",
        "        \n",
        "    # Flatten images into a 784 long vector\n",
        "    images.resize_(images.size()[0], 784)\n",
        "        \n",
        "    optimizer.zero_grad()\n",
        "        \n",
        "    output = model.forward(images)\n",
        "    loss = criterion(output, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "        \n",
        "    running_loss += loss.item()\n",
        "        \n",
        "    if steps % print_every == 0:\n",
        "      # Make sure network is in eval mode for inference\n",
        "      model.eval()\n",
        "            \n",
        "      # Turn off gradients for validation, saves memory and computations\n",
        "      with torch.no_grad():\n",
        "        test_loss, accuracy = validation(model, testloader, criterion)\n",
        "                \n",
        "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\\\n",
        "                  \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\\\n",
        "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\\\n",
        "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
        "            \n",
        "        running_loss = 0\n",
        "            \n",
        "        # Make sure training is back on\n",
        "        model.train()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/4..  Training Loss: 0.230..  Test Loss: 0.128..  Test Accuracy: 0.962\n",
            "Epoch: 1/4..  Training Loss: 0.243..  Test Loss: 0.132..  Test Accuracy: 0.961\n",
            "Epoch: 1/4..  Training Loss: 0.231..  Test Loss: 0.127..  Test Accuracy: 0.961\n",
            "Epoch: 1/4..  Training Loss: 0.242..  Test Loss: 0.137..  Test Accuracy: 0.959\n",
            "Epoch: 1/4..  Training Loss: 0.254..  Test Loss: 0.132..  Test Accuracy: 0.960\n",
            "Epoch: 1/4..  Training Loss: 0.228..  Test Loss: 0.141..  Test Accuracy: 0.958\n",
            "Epoch: 1/4..  Training Loss: 0.217..  Test Loss: 0.129..  Test Accuracy: 0.959\n",
            "Epoch: 1/4..  Training Loss: 0.225..  Test Loss: 0.131..  Test Accuracy: 0.960\n",
            "Epoch: 1/4..  Training Loss: 0.236..  Test Loss: 0.136..  Test Accuracy: 0.960\n",
            "Epoch: 1/4..  Training Loss: 0.240..  Test Loss: 0.130..  Test Accuracy: 0.961\n",
            "Epoch: 1/4..  Training Loss: 0.236..  Test Loss: 0.142..  Test Accuracy: 0.956\n",
            "Epoch: 1/4..  Training Loss: 0.245..  Test Loss: 0.127..  Test Accuracy: 0.961\n",
            "Epoch: 1/4..  Training Loss: 0.239..  Test Loss: 0.133..  Test Accuracy: 0.959\n",
            "Epoch: 1/4..  Training Loss: 0.251..  Test Loss: 0.127..  Test Accuracy: 0.962\n",
            "Epoch: 1/4..  Training Loss: 0.233..  Test Loss: 0.133..  Test Accuracy: 0.960\n",
            "Epoch: 1/4..  Training Loss: 0.265..  Test Loss: 0.122..  Test Accuracy: 0.963\n",
            "Epoch: 1/4..  Training Loss: 0.227..  Test Loss: 0.125..  Test Accuracy: 0.963\n",
            "Epoch: 1/4..  Training Loss: 0.230..  Test Loss: 0.126..  Test Accuracy: 0.962\n",
            "Epoch: 1/4..  Training Loss: 0.283..  Test Loss: 0.129..  Test Accuracy: 0.960\n",
            "Epoch: 1/4..  Training Loss: 0.200..  Test Loss: 0.121..  Test Accuracy: 0.963\n",
            "Epoch: 1/4..  Training Loss: 0.209..  Test Loss: 0.127..  Test Accuracy: 0.959\n",
            "Epoch: 1/4..  Training Loss: 0.232..  Test Loss: 0.137..  Test Accuracy: 0.957\n",
            "Epoch: 1/4..  Training Loss: 0.229..  Test Loss: 0.126..  Test Accuracy: 0.961\n",
            "Epoch: 2/4..  Training Loss: 0.269..  Test Loss: 0.123..  Test Accuracy: 0.963\n",
            "Epoch: 2/4..  Training Loss: 0.198..  Test Loss: 0.122..  Test Accuracy: 0.964\n",
            "Epoch: 2/4..  Training Loss: 0.209..  Test Loss: 0.128..  Test Accuracy: 0.960\n",
            "Epoch: 2/4..  Training Loss: 0.242..  Test Loss: 0.134..  Test Accuracy: 0.960\n",
            "Epoch: 2/4..  Training Loss: 0.205..  Test Loss: 0.130..  Test Accuracy: 0.961\n",
            "Epoch: 2/4..  Training Loss: 0.225..  Test Loss: 0.118..  Test Accuracy: 0.963\n",
            "Epoch: 2/4..  Training Loss: 0.204..  Test Loss: 0.125..  Test Accuracy: 0.962\n",
            "Epoch: 2/4..  Training Loss: 0.236..  Test Loss: 0.128..  Test Accuracy: 0.962\n",
            "Epoch: 2/4..  Training Loss: 0.266..  Test Loss: 0.123..  Test Accuracy: 0.964\n",
            "Epoch: 2/4..  Training Loss: 0.217..  Test Loss: 0.121..  Test Accuracy: 0.964\n",
            "Epoch: 2/4..  Training Loss: 0.233..  Test Loss: 0.124..  Test Accuracy: 0.963\n",
            "Epoch: 2/4..  Training Loss: 0.213..  Test Loss: 0.134..  Test Accuracy: 0.960\n",
            "Epoch: 2/4..  Training Loss: 0.206..  Test Loss: 0.121..  Test Accuracy: 0.964\n",
            "Epoch: 2/4..  Training Loss: 0.216..  Test Loss: 0.114..  Test Accuracy: 0.967\n",
            "Epoch: 2/4..  Training Loss: 0.223..  Test Loss: 0.120..  Test Accuracy: 0.965\n",
            "Epoch: 2/4..  Training Loss: 0.198..  Test Loss: 0.123..  Test Accuracy: 0.962\n",
            "Epoch: 2/4..  Training Loss: 0.222..  Test Loss: 0.122..  Test Accuracy: 0.962\n",
            "Epoch: 2/4..  Training Loss: 0.245..  Test Loss: 0.113..  Test Accuracy: 0.965\n",
            "Epoch: 2/4..  Training Loss: 0.232..  Test Loss: 0.112..  Test Accuracy: 0.966\n",
            "Epoch: 2/4..  Training Loss: 0.215..  Test Loss: 0.120..  Test Accuracy: 0.962\n",
            "Epoch: 2/4..  Training Loss: 0.269..  Test Loss: 0.124..  Test Accuracy: 0.961\n",
            "Epoch: 2/4..  Training Loss: 0.230..  Test Loss: 0.114..  Test Accuracy: 0.966\n",
            "Epoch: 2/4..  Training Loss: 0.224..  Test Loss: 0.114..  Test Accuracy: 0.966\n",
            "Epoch: 3/4..  Training Loss: 0.219..  Test Loss: 0.125..  Test Accuracy: 0.962\n",
            "Epoch: 3/4..  Training Loss: 0.201..  Test Loss: 0.112..  Test Accuracy: 0.965\n",
            "Epoch: 3/4..  Training Loss: 0.227..  Test Loss: 0.115..  Test Accuracy: 0.963\n",
            "Epoch: 3/4..  Training Loss: 0.220..  Test Loss: 0.123..  Test Accuracy: 0.963\n",
            "Epoch: 3/4..  Training Loss: 0.216..  Test Loss: 0.118..  Test Accuracy: 0.965\n",
            "Epoch: 3/4..  Training Loss: 0.217..  Test Loss: 0.122..  Test Accuracy: 0.963\n",
            "Epoch: 3/4..  Training Loss: 0.189..  Test Loss: 0.125..  Test Accuracy: 0.962\n",
            "Epoch: 3/4..  Training Loss: 0.207..  Test Loss: 0.115..  Test Accuracy: 0.963\n",
            "Epoch: 3/4..  Training Loss: 0.215..  Test Loss: 0.116..  Test Accuracy: 0.966\n",
            "Epoch: 3/4..  Training Loss: 0.225..  Test Loss: 0.122..  Test Accuracy: 0.966\n",
            "Epoch: 3/4..  Training Loss: 0.210..  Test Loss: 0.108..  Test Accuracy: 0.968\n",
            "Epoch: 3/4..  Training Loss: 0.201..  Test Loss: 0.119..  Test Accuracy: 0.962\n",
            "Epoch: 3/4..  Training Loss: 0.228..  Test Loss: 0.117..  Test Accuracy: 0.963\n",
            "Epoch: 3/4..  Training Loss: 0.238..  Test Loss: 0.114..  Test Accuracy: 0.966\n",
            "Epoch: 3/4..  Training Loss: 0.214..  Test Loss: 0.130..  Test Accuracy: 0.961\n",
            "Epoch: 3/4..  Training Loss: 0.198..  Test Loss: 0.112..  Test Accuracy: 0.965\n",
            "Epoch: 3/4..  Training Loss: 0.191..  Test Loss: 0.122..  Test Accuracy: 0.964\n",
            "Epoch: 3/4..  Training Loss: 0.226..  Test Loss: 0.115..  Test Accuracy: 0.966\n",
            "Epoch: 3/4..  Training Loss: 0.198..  Test Loss: 0.120..  Test Accuracy: 0.964\n",
            "Epoch: 3/4..  Training Loss: 0.208..  Test Loss: 0.119..  Test Accuracy: 0.963\n",
            "Epoch: 3/4..  Training Loss: 0.215..  Test Loss: 0.113..  Test Accuracy: 0.968\n",
            "Epoch: 3/4..  Training Loss: 0.187..  Test Loss: 0.123..  Test Accuracy: 0.964\n",
            "Epoch: 3/4..  Training Loss: 0.239..  Test Loss: 0.116..  Test Accuracy: 0.966\n",
            "Epoch: 3/4..  Training Loss: 0.185..  Test Loss: 0.109..  Test Accuracy: 0.970\n",
            "Epoch: 4/4..  Training Loss: 0.232..  Test Loss: 0.110..  Test Accuracy: 0.968\n",
            "Epoch: 4/4..  Training Loss: 0.233..  Test Loss: 0.111..  Test Accuracy: 0.966\n",
            "Epoch: 4/4..  Training Loss: 0.219..  Test Loss: 0.122..  Test Accuracy: 0.960\n",
            "Epoch: 4/4..  Training Loss: 0.214..  Test Loss: 0.115..  Test Accuracy: 0.965\n",
            "Epoch: 4/4..  Training Loss: 0.208..  Test Loss: 0.113..  Test Accuracy: 0.966\n",
            "Epoch: 4/4..  Training Loss: 0.191..  Test Loss: 0.117..  Test Accuracy: 0.964\n",
            "Epoch: 4/4..  Training Loss: 0.185..  Test Loss: 0.108..  Test Accuracy: 0.969\n",
            "Epoch: 4/4..  Training Loss: 0.202..  Test Loss: 0.107..  Test Accuracy: 0.967\n",
            "Epoch: 4/4..  Training Loss: 0.199..  Test Loss: 0.113..  Test Accuracy: 0.967\n",
            "Epoch: 4/4..  Training Loss: 0.219..  Test Loss: 0.115..  Test Accuracy: 0.965\n",
            "Epoch: 4/4..  Training Loss: 0.217..  Test Loss: 0.114..  Test Accuracy: 0.966\n",
            "Epoch: 4/4..  Training Loss: 0.199..  Test Loss: 0.109..  Test Accuracy: 0.966\n",
            "Epoch: 4/4..  Training Loss: 0.208..  Test Loss: 0.122..  Test Accuracy: 0.964\n",
            "Epoch: 4/4..  Training Loss: 0.218..  Test Loss: 0.119..  Test Accuracy: 0.962\n",
            "Epoch: 4/4..  Training Loss: 0.233..  Test Loss: 0.112..  Test Accuracy: 0.966\n",
            "Epoch: 4/4..  Training Loss: 0.191..  Test Loss: 0.108..  Test Accuracy: 0.967\n",
            "Epoch: 4/4..  Training Loss: 0.205..  Test Loss: 0.113..  Test Accuracy: 0.965\n",
            "Epoch: 4/4..  Training Loss: 0.198..  Test Loss: 0.109..  Test Accuracy: 0.967\n",
            "Epoch: 4/4..  Training Loss: 0.192..  Test Loss: 0.109..  Test Accuracy: 0.967\n",
            "Epoch: 4/4..  Training Loss: 0.204..  Test Loss: 0.109..  Test Accuracy: 0.968\n",
            "Epoch: 4/4..  Training Loss: 0.163..  Test Loss: 0.114..  Test Accuracy: 0.966\n",
            "Epoch: 4/4..  Training Loss: 0.192..  Test Loss: 0.117..  Test Accuracy: 0.966\n",
            "Epoch: 4/4..  Training Loss: 0.199..  Test Loss: 0.117..  Test Accuracy: 0.964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spoRulHxYAEX"
      },
      "source": [
        "## Inference\n",
        "\n",
        "Now that the model is trained, you can use it for inference. You need to set the model in inference mode with `model.eval()`. You'll also want to turn off autograd with the `torch.no_grad()` context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TROE49zKX5_U"
      },
      "source": [
        "# Test out your network!\n",
        "\n",
        "model.eval()\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "img = images[1]\n",
        "# Convert 2D image to 1D vector\n",
        "img = img.view(1, 784)\n",
        "\n",
        "# Calculate the class probabilities (softmax) for img\n",
        "with torch.no_grad():\n",
        "    output = model.forward(img)\n",
        "\n",
        "ps = torch.exp(output)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOlZKfqz8Jrz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f88ae353-3efd-462f-d6b1-3b5f0224e5df"
      },
      "source": [
        "ps"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.8814e-11, 1.5342e-04, 4.7614e-06, 9.9974e-01, 1.1505e-07, 5.7978e-05,\n",
              "         2.5402e-11, 4.2008e-07, 2.7943e-05, 1.4944e-05]])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxr2Y0GdnLeN"
      },
      "source": [
        "\n",
        "def view_classify(img, ps):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRk-xZWLYCN2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "e6aa6192-3156-47d5-f1d9-c2e4220903bc"
      },
      "source": [
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADsCAYAAAAhDDIOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVNElEQVR4nO3de7RdZXnv8e+PBIRIiEii5RJMlIBQHCKmDLH1VpACMsBztB0g2GKpHK+Hm7bU2mrtaUc9eKnnqFWqeKmKgEWkCAoVFPWQSBIQwrWIBBIQAmKAIJckz/ljLRy7mz2Tnc3amXOF72eMNbLWfOZc69k7gd9+3/nuOVNVSJLUNVu03YAkSWMxoCRJnWRASZI6yYCSJHWSASVJ6iQDSpLUSQaUpEmT5INJvtJ2HxsryZwklWTqBI+vJLs11I5OcvFY+yb5TJK/nljXmx8DStJTkuRNSRYleSjJXUkuSvJ7LfVSSVb3e1mR5GNJprTRS5Oq+mpVHdRQe1tV/R1AklcnWb5pu+sWA0rShCU5Gfgn4B+A5wK7Ap8GjmixrRdX1bbAAcCbgLeO3mGiIyNtWgaUpAlJMgP4EPDOqjq3qlZX1eNV9e9V9d6GY85J8oskq5JcnuS3R9QOTXJ9kgf7o5/39LfPTHJBkl8l+WWSHybZ4P+7qupG4IfA3iOm7I5LcjtwaZItkrw/ybIk9yT5cv9rGulPk9zZHxm+Z0Sv+yW5ot/TXUk+mWSrUccemuTWJPcmOe2JnpMcm+RHDd+fLyb5X0meCVwE7NQfDT6UZKckDyfZYcT++yZZmWTLDX0/hpEBJWmi9ge2Br65EcdcBMwDngMsAb46ovZ54H9U1XRgb+DS/vZTgOXALHqjtPcBG7xGW5K9gFcAV43Y/CpgT+APgGP7j9cAzwe2BT456m1e0+/3IOAvkhzY374WOAmYSe/7cADwjlHH/jdgPrAvvRHln26o5ydU1WrgEODOqtq2/7gT+D7wRyN2fTPw9ap6fLzvPUwMKEkTtQNwb1WtGe8BVXVGVT1YVY8CHwRePGLU8jiwV5Ltqur+qloyYvuOwPP6I7Qf1vovIrokyf3AvwOfA74wovbB/kjv18DRwMeq6taqegj4S+DIUdN/f9vf/9r++xzV/zoWV9WCqlpTVbcBn6UXfiN9uKp+WVW305sGPWq836f1+BJwDED/3NpRwL8O4H07yYCSNFH3ATPHez4nyZQk/5jkZ0keAG7rl2b2/3wDcCiwLMkPkuzf334acAtwcX/K7NQNfNS+VbV9Vb2gqt5fVetG1O4Y8XwnYNmI18uAqfRGaWPtv6x/DEl27087/qL/tfzDiK9jvcc+Rd+iF+JzgdcCq6rqJwN4304yoCRN1BXAo8Drx7n/m+hNdR0IzADm9LcHoKqurKoj6E3/nQec3d/+YFWdUlXPBw4HTk5ywAR7HjnyuhN43ojXuwJrgLtHbJs9qn5n//k/AzcC86pqO3rTjhn1WU3HTqTX3oaqR+h9X46hN7232Y6ewICSNEFVtQr4G+BTSV6fZFqSLZMckuR/j3HIdHqBdh8wjd6oA4AkW/V/P2hG/3zKA8C6fu2wJLslCbCK3vmfdU969413JnBSkrlJtu33c9aoKcu/7n9dvw28BThrxNfyAPBQkhcCbx/j/d+bZPsks4ETRhw7XncDO4yxcOPL9M6dHY4BJUljq6qPAicD7wdW0pvWehe9EdBoX6Y31bUCuB5YMKr+ZuC2/pTZ2+idI4LeIoX/AB6iN2r7dFVdNoD2z6D3P/jLgZ8DjwDvHrXPD+hNL34P+EhVPfELtu+hNyJ8EPgXxg6fbwGLgauBb9NbBDJu/VWIZwK39lcL7tTf/mN6Ab2kqpat7z2GXbxhoSQNlySXAl+rqs+13ctkMqAkaYgk+R3gEmB2VT3Ydj+TySk+SRoSSb5Eb7rzxM09nMARlCSpo9b7+wuv3eIPTS897V2y7pzRy4clbQJO8UmSOskr+kotmjlzZs2ZM6ftNqRWLV68+N6qmjV6uwEltWjOnDksWrSo7TakViUZ8/e5nOKTJHWSASVJ6iQDSpLUSQaUJKmTDChJUicZUJKkTjKgJEmdZEBJkjrJgJIkdZIBJUnqJANKGrAkJyRZmuS6JCe23Y80rAwoaYCS7A28FdgPeDFwWJLd2u1KGk4GlDRYewILq+rhqloD/AD47y33JA0lA0oarKXAK5LskGQacCgwe+QOSY5PsijJopUrV7bSpDQMDChpgKrqBuDDwMXAd4CrgbWj9jm9quZX1fxZs550CxxJfQaUNGBV9fmqemlVvRK4H7i57Z6kYeQNC6UBS/Kcqronya70zj+9rO2epGFkQEmD929JdgAeB95ZVb9quyFpGBlQ0oBV1Sva7kHaHHgOSpLUSQaUJKmTDChJUicZUJKkTnKRxCayxT57Ndbu22dGY+0P33PxhD7vh/fNa6wtvXpOY23eCQsm9HmSNGiOoCRJnWRASZI6yYCSJHWSASUNWJKT+jcrXJrkzCRbt92TNIwMKGmAkuwM/E9gflXtDUwBjmy3K2k4GVDS4E0FtkkyFZgG3NlyP9JQcpn5AN3y8eaLVl/2ho801naeMq2xto6aUC8nbt98h4fv7dz8eR8/Yc8JfZ56qmpFko8AtwO/Bi6uqon9roD0NOcIShqgJNsDRwBzgZ2AZyY5ZtQ+3lFXGgcDShqsA4GfV9XKqnocOBd4+cgdvKOuND4GlDRYtwMvSzItSYADgBta7kkaSgaUNEBVtRD4BrAEuJbef2Ont9qUNKRcJCENWFV9APhA231Iw84RlCSpkxxBDdCUHR9urN2xpnlp99Envr2xtt2VKybUy8NnTGmsXbzXuY21k//q5Y212X///ybUiyRNhCMoSVInGVCSpE4yoCRJnWRASZI6yYCSJHWSq/gGaO6R1zTWPsS+jbVpLGysrZlgL6sfmzeh4174B//Z/J5/P8FmJGkCHEFJkjrJgJIGKMkeSa4e8XggyYlt9yUNI6f4pAGqqpuAfQCSTAFWAN9stSlpSDmCkibPAcDPqmpZ241Iw8iAkibPkcCZozd6w0JpfAwoaRIk2Qo4HDhndM0bFkrj4zko/Rf3fnRuY20b/Gl/IxwCLKmqu9tuRBpWjqCkyXEUY0zvSRo/A0oasCTPBF4LNN/XRNIGOcUnDVhVrQZ2aLsPadg5gpIkdZIBJUnqJANKktRJnoMaYiv+4uWNtZ/u88nG2p/d8erG2jbf+slTaUmSBsYRlCSpkwwoSVInGVCSpE4yoCRJnWRASQOW5FlJvpHkxiQ3JNm/7Z6kYeQqPmnwPgF8p6re2L+q+bS2G5KGkQHVcVP22K2xdu47TmusLXh0m8basr/Zo7G2JYvG15jGlGQG8ErgWICqegx4rM2epGHlFJ80WHOBlcAXklyV5HP9i8dK2kgGlDRYU4F9gX+uqpcAq4FTR+7gHXWl8TGgpMFaDiyvqoX919+gF1i/4R11pfExoKQBqqpfAHckeeJE3wHA9S22JA0tF0lIg/du4Kv9FXy3Am9puR9pKBlQ0oBV1dXA/Lb7kIadAdUBU3f8rcZa3Xd/Y+3BdVs21v74/Hc01na7eMH4GpOkFnkOSpLUSQaUJKmTDChJUicZUJKkTjKgJEmdZEBJkjrJZeYDVPu/uLG2/MDm64We92fNVyX/5MpXN9a2ztrG2gs/vqKxtqaxIknd4QhKktRJjqCkAUtyG/AgsBZYU1VeVUKaAANKmhyvqap7225CGmZO8UmSOsmAkgavgIuTLE5y/OiiNyyUxseAkgbv96pqX+AQ4J1JXjmy6A0LpfHxHNRGmvOTbRprpzz30421uVO3bqxtQfN7fnTH9V15fKvGyt0H7dJYe/b1OzTW8uOr1/N5Go+qWtH/854k3wT2Ay5vtytp+DiCkgYoyTOTTH/iOXAQsLTdrqTh5AhKGqznAt9MAr3/vr5WVd9ptyVpOBlQ0gBV1a1A8yVFJI2bU3ySpE4yoCRJnWRASZI6yXNQG+ml05c11nbfsvmK5dc89khj7Qer92isrSWNteNn3NxY2+mYnzfWll49p7G2wx77N9aefcYVjTVJGjRHUJKkTjKgJEmdZEBJkjrJgJIkdZIBJUnqJANKmgRJpiS5KskFbfciDSuXmW+k8974isbaV+bNaKxNW7a6sVZXXTexXg59Z2Pt9kObf/Y46cCLGmvPf93djbVPX3JgY23NHcsba09TJwA3ANu13Yg0rBxBSQOWZBfgdcDn2u5FGmYGlDR4/wT8ObBurKJ31JXGx4CSBijJYcA9VbW4aR/vqCuNjwElDdbvAocnuQ34OvD7Sb7SbkvScDKgpAGqqr+sql2qag5wJHBpVR3TclvSUDKgJEmd5DLzjbT2upsaa9usZ7V4TUIvz7jwysbavAubj7vrqubl8Bcc96rGWmaubX5Tl5k/SVV9H/h+y21IQ8sRlCSpkwwoSVInGVCSpE4yoCRJneQiCalF165YxZxTv912G9KE3PaPr5vU93cEJUnqJEdQT0ML75vTWJv+4earmd98yQsaa7OveiodSdKTOYKSJHWSASUNUJKtk/wkyU+TXJfkb9vuSRpWTvFJg/Uo8PtV9VCSLYEfJbmoqha03Zg0bAwoaYCqqoCH+i+37D8m40pX0mbPKT5pwJJMSXI1cA9wSVUtbLsnaRgZUNKAVdXaqtoH2AXYL8neI+sj76i79uFV7TQpDQGn+DZTjx80v7F29h6faKzduXZKY+3Pv31cY805rCerql8luQw4GFg6YvvpwOkAz9hxnt86qYEjKGmAksxK8qz+822A1wI3ttuVNJwcQUmDtSPwpSRT6P0AeHZVXdByT9JQMqCkAaqqa4CXtN2HtDlwik+S1EkGlCSpk5zik1r0op1nsGiSb1kgDSsDaohtMX16Y+22I5qXi69vKfnrLzihsTbvKn/fVNKm4xSfJKmTDChJUicZUJKkTjKgJEmdZEBJkjrJgJIGKMnsJJclub5/R93mZZGS1stl5h03ZY/dGmu/OK15uTh3NJeWPLJrY23eu1xK/hStAU6pqiVJpgOLk1xSVde33Zg0bBxBSQNUVXdV1ZL+8weBG4Cd2+1KGk4GlDRJksyhd+HYhaO2/+aGhStXrmyjNWkoGFDSJEiyLfBvwIlV9cDIWlWdXlXzq2r+rFmz2mlQGgIGlDRgSbakF05frapz2+5HGlYGlDRASQJ8Hrihqj7Wdj/SMBuaVXxTnjWjsbbbfzw85vbLzv6dxmN2PWs9y9zWox5a3Vi76f27T+g9f2vPexprb9q1eVXdn2z3n421fa8/qbH2xZOOaKw9gysbaxqX3wXeDFyb5Or+tvdV1YUt9iQNpaEJKGkYVNWPgLTdh7Q5cIpPktRJBpQkqZMMKElSJxlQkqROMqAkSZ00NKv46vE1jbV1NXbOLjnh/zYes8UJzQut1lGNtd0veFtj7ebDPtVYW5+71/66sXbq8sMaa2d8ork297NXTKgXbVrXrljVdgtSZzmCkiR1kgElSeokA0oaoCRnJLknydK2e5GGnQElDdYXgYPbbkLaHBhQ0gBV1eXAL9vuQ9ocGFCSpE4ammXm61Y3X0X81qNfMOb2w579lsZjVr7v0cbawpd+rbF282Gfaaytz36Ljm6sTT1v+8bas7/QvFx8Ji4lH0ZJjgeOB5iynTcslJo4gpI2sZF31J0yrfk2MtLTnQElSeokA0oaoCRnAlcAeyRZnuS4tnuShtXQnIOShkFVHdV2D9LmwhGUJKmTDChJUidtFlN8a2/+2UYfM+vw5tphvPQpdDO253DjwN9Tw+9FO7uKT2riCEqS1EkGlCSpkwwoSVInGVCSpE4yoCRJnWRASZI6yYCSBizJwUluSnJLklPb7kcaVgaUNEBJpgCfAg4B9gKOSrJXu11Jw8mAkgZrP+CWqrq1qh4Dvg4c0XJP0lAyoKTB2hm4Y8Tr5f1tv5Hk+CSLkixauXLlJm1OGiYGlLSJjbxh4axZ3lFXamJASYO1Apg94vUu/W2SNpIBJQ3WlcC8JHOTbAUcCZzfck/SUNosrmYudUVVrUnyLuC7wBTgjKq6ruW2pKFkQEkDVlUXAhe23Yc07JzikyR1kgElSeokA0qS1EkGlCSpkwwoSVInGVCSpE4yoCRJnWRASZI6yYCSJHWSASVJ6iQvdSS1aPHixQ8luantPkaYCdzbdhN99jK2zbGX54210YCS2nVTVc1vu4knJFnUlX7sZWxPp17WG1CXrDsnk/XBkiStj+egJEmdZEBJ7Tq97QZG6VI/9jK2p00vqarJfH9JkibEEZQkqZMMKGkTSHJwkpuS3JLk1DHqz0hyVr++MMmcFns5Ocn1Sa5J8r0kYy4B3hS9jNjvDUkqyaSuXhtPP0n+qP/9uS7J19rqJcmuSS5LclX/7+rQSerjjCT3JFnaUE+S/9Pv85ok+w7sw6vKhw8fk/gApgA/A54PbAX8FNhr1D7vAD7Tf34kcFaLvbwGmNZ//vY2e+nvNx24HFgAzG/572kecBWwff/1c1rs5XTg7f3newG3TVIvrwT2BZY21A8FLgICvAxYOKjPdgQlTb79gFuq6taqegz4OnDEqH2OAL7Uf/4N4IAkk/FrHhvspaouq6qH+y8XALtMQh/j6qXv74APA49MUh8b089bgU9V1f0AVXVPi70UsF3/+QzgzslopKouB365nl2OAL5cPQuAZyXZcRCfbUBJk29n4I4Rr5f3t425T1WtAVYBO7TUy0jH0fvpeDJssJf+dNHsqvr2JPWwUf0AuwO7J/lxkgVJDm6xlw8CxyRZDlwIvHuSetmQjf03NW5eSULSmJIcA8wHXtXS528BfAw4to3PbzCV3jTfq+mNLC9P8qKq+lULvRwFfLGqPppkf+Bfk+xdVeta6GVSOIKSJt8KYPaI17v0t425T5Kp9KZs7mupF5IcCPwVcHhVPToJfYynl+nA3sD3k9xG7/zG+ZO4UGI835vlwPlV9XhV/Ry4mV5gtdHLccDZAFV1BbA1vWvjbWrj+jc1EQaUNPmuBOYlmZtkK3qLIM4ftc/5wJ/0n78RuLT6Z6A3dS9JXgJ8ll44TdY5lg32UlWrqmpmVc2pqjn0zocdXlWL2uin7zx6oyeSzKQ35XdrS73cDhzQ72VPegG1chJ62ZDzgT/ur+Z7GbCqqu4axBs7xSdNsqpak+RdwHfprc46o6quS/IhYFFVnQ98nt4UzS30Tkgf2WIvpwHbAuf012ncXlWHt9TLJjPOfr4LHJTkemAt8N6qGvhId5y9nAL8S5KT6C2YOHYyfqhJcia9UJ7ZP9/1AWDLfp+foXf+61DgFuBh4C0D++zJ+SFNkqSnxik+SVInGVCSpE4yoCRJnWRASZI6yYCSJHWSASVJ6iQDSpLUSQaUJKmT/j8vJYtzYLyVpwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4z6shFxxbCiP"
      },
      "execution_count": 122,
      "outputs": []
    }
  ]
}